# Evaluation und Bewertung

## Hochverfügbares Elixir vs Single Node
Immer mehr Alltagsanwendungen sind heutzutage über das Internet via Webbrowser erreichbar. Diese "Software as a Service" Produkte müssen dabei hohen Anforderungen gerecht werden. Im Mittelpunkt stehen beispielsweise Eigenschaften wie "Zero Downtime" und hohe Reaktionszeiten der Software. Das Synonym "Zero Downtime" bedeutet dabei, dass die Anwendung jederzeit verfügbar ist, also auch wenn nebenbei Software-Updates stattfinden oder die Datenbank migriert wird. Hohe Reaktionszeiten sind dabei maßgeblich für eine gute "User-Experience" verantwortlich. Diese ist wiederum eng verknüpft mit der durch den Benutzenden wahrgenommenen Qualität der Anwendung. Diese Hohe Software-Verfügbarkeit von verteilten Anwendungen kann dabei über zwei Wege erreicht werden. Man kann zum einen vertikal skalieren, indem man die Instanz, auf welcher die Anwendung läuft, mit mehr Ressourcen ausstattet. Oder man kann zum anderen horizontal skalieren, indem man einfach mehr Instanzen der Anwendung, sogenannte Replikationen, parallel betreibt. 

Genau an diesem Punkt kommt Kubernetes ins Spiel. Kubernetes ist genau für eine solche horizontale Skalierung ausgelegt. In den zuvor beschriebenen Deployment-Konfiguration kann angegeben werden, wie viele Replikas der Anwendung parallel laufen sollen. Dies wird dadurch bewerkstelligt, dass von der Anwendungskonfiguration sogenannte "Blueprints", also exakte "Klone" der Anwendung gestartet werden, welche dann über verschiedene IP-Adressen erreichbar sind. In diesen Anwendungskonfigurationen wiederum wird das container-Image der Anwendung angegeben, welches beispielsweise ein Docker Image sein kann, wie in der im Prototypen verwendeten Anwendung. Hällt man sich an die Namensgebung von Kubernetes, laufen die Anwendungen dann in sogenannten Pods. Ein [Pod](https://kubernetes.io/de/docs/concepts/workloads/pods/) ist also eine Abstraktion von einem oder mehreren Containern, welche gemeinsam dieselben Speicher- und Netzwerkressourcen nutzen, sowie eine gemeinsame Spezifikation für die Ausführung dieser Container teilen. Ein sogenannter LoadBalancer entscheidet dann beispielsweise anhand der aktuellen Auslastung der Instanzen, auf welche Instanz ein neuer Client weitergeleitet wird. Nun fehlt nur noch die Erklärung der zwei Fachbegriffe "Node" und "Cluster" um, auf die Hochverfügbarkeit von Elixir ansich eingehen zu können. Kubernetes führt "workload" bzw. Arbeitslast aus, indem es Container in Pods platziert, die anschließend auf ["Nodes"](https://kubernetes.io/docs/concepts/architecture/nodes/) ausgeführt werden. Jeder dieser Knoten wird von der Steuerungsebene verwaltet und bündelt die für den Betrieb von Pods erforderlichen Dienste. Normalerweise werden dann mehrere dieser Knoten in einem Cluster, also einem Verbund bzw. einer Gruppe dieser Knoten betrieben, auf denen von Kubernetes verwaltete containerisierte Anwendungen laufen.

Elixir-Anwendungen lassen sich perfekt in dieses Konzept integrieren. Elixir besitzt dabei alle notwendigen verteilten Funktionen, welche benötigt werden, um ein Cluster zwischen den verschiedenen Instanzen der jeweiligen Anwendungen aufbauen zu können. Dafür werden keine zusätzlichen Abhängigkeiten benötigt. Um so ein Cluster aufzusetzen, muss jeder Anwendungsinstanz ein Name zugewiesen werden, welcher bestimmte Konventionen erfüllen muss. Anschließend können die erzeugten Knoten miteinander verbunden werden. Dies läuft über Angabe eines festgelegten eindeutigen Namens via der ["connect"](https://hexdocs.pm/elixir/1.12/Node.html#connect/1) Funktion des Elixir-Node-Moduls. Der Name muss dabei folgendes Format haben \<app-name\>@\<node-ip\>. Ist die IP-Adresse immer dieselbe, muss jedoch der \<app-name\> den Knoten eindeutig identifizieren, also variieren. Dieser kann im Kubernetes Deployment über das Setzen der Umgebungsvariable [RELEASE_NODE](https://hexdocs.pm/mix/Mix.Tasks.Release.html) dynamisch zugewiesen werden. Um nicht bei jedem Start eines neuen Knotens manuell die genannte "connect" Funktion aufrufen zu müssen, um Cluster zu bilden, gibt es die Elixir-Bibliothek [libcluster](https://hexdocs.pm/libcluster/readme.html). Sie erlaubt die automatische Clusterbildung aus Erlangknoten. Dies kann dynamisch oder statisch passieren. Dynamisch bedeutet dabei, dass sich die Knoten automatisch über einen Erkennungsmechanismus wie beispielsweise DNS finden und formieren können. Um dies zu erreichen, kann eine Vielzahl von verschiedenen Formierungsstrategien wie [Kubernetes DNS](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/) oder [epmd](https://www.erlang.org/doc/man/epmd.html) genutzt werden. Der Erlang Epmd-Deamon fungiert dabei als Namenserver in verteilten Erlang und damit auch Elixir Umgebungen. Damit man an dieser Stelle nicht an die Implementierung von Kubernetes gebunden ist, wird eine Schnittstelle mit dem Namen "Headless Services" für eigene Service-Erkennungsmechanismen bereitgestellt. Diese Bibliothek wurde auch beim Aufbau des Prototypen dieser Arbeit verwendet.

![Elixir-Node-Cluster](https://github.com/Elixir2K8s/docs/blob/main/Libcluster.png)


## Hochverfügbare Datenbank vs einzelne Instanz

Nachdem die Elixir-Anwendung hochverfügbar gemacht wurde, ist die Postgres-Datenbank der letzte verbleibende Single Point of Failure, innerhalb des Kubernetes-Clusters.

Um diesen zu Eliminieren muss die Datenbank hochverfügbar gemacht werden. Hierfür sind mindestens zwei PostgresDB Pods erforderlich, wobei einer als Primary und die restlichen als Replica arbeiten. Für das Load Balancing und Failover zwischen den DB Pods kommt pgpool-II zum Einsatz. Das Failover zwischen Primary und Replicas wird durch den postgresql-repmgr verwaltet. Dieser promotet eine Replica zum neuen Primary, falls der bestehende Primary ausfällt.

Das [HA Postgres Setup von Bitnami](https://github.com/bitnami/charts/tree/master/bitnami/postgresql-ha) besteht aus einer Sammlung von K8s Service Definitions, die über einen Helm Chart installiert werden. Helm ist im übertragenen Sinne ein Paketmanager für Kubernetes Service Definitions, die eine Anwendung deployen. Um Helm in MicroK8s zu nutzen, muss Helm erst als Addon aktiviert werden.

Nachdem die Parameter des [Bitnami Postgres HA Helm Charts](https://github.com/bitnami/charts/tree/master/bitnami/postgresql-ha#global-parameters) wie gewünscht konfiguriert wurden kann dieser via Helm installiert werden und ist danach einsatzbereit.

Im Vergleich zur Variante mit einer einzelnen Postgres Instanz ist dies ein signifikanter Mehraufwand. bei der Konfiguration und Deployment, da man zusätzlich zu den eigenen Service Definitions einen Helm Chart hat, dessen Konfiguration es auch entsprechend zu warten gilt. Bei der einzelnen Datenbank hingegen kann das Deployment einfach zusammen mit der Elixir-Anwendung mit dem selben Befehl erfolgen, da die Service Definitions im gleichen Verzeichnis liegen. Auch bei der Konfiguration war durchaus weniger zu beachten, da die Service Definitions für die einzelne PostgresDB mit kompose aus der docker-compose Datei generiert werden konnten.

Betrachtet man den Aspekt der Hochverfügbarkeit bzw. Ausfallsicherheit ist es durchaus sinnvoll auf einen hochverfügbaren Postgres Helm Chart zu setzen, da einzelne Nodes im Kubernetes Cluster ausfallen können und dies bei einer einzelnen Datenbank zu einem temporären Komplettausfall der Anwendung führen würde. Da im Rahmen des Praktikums jedoch nur ein Single Node Kubernetes Cluster genutzt wird, bietet der Einsatz des Postgres HA Charts keine Vorteile unter dem Aspekt der physischen Ausfallsicherheit. Der einzige nennenswerte Vorteil des HA DB Setups in Kombination mit einem Single Node K8s Cluster ist die unterbrechungsfreie Upgrademöglichkeit der Datenbank, jedoch ist diese Funktionalität für ein Test Deployment vernachlässigbar.

Daher bleiben wir für das Test Deployment auf einem Single Node K8s Cluster bei einer einzelnen Postgres-Instanz.

Alternativ zu einer klassischen SQL-Datenbank, ließe sich auch auf das in Erlang geschriebene Mnesia Datenbanksystem setzen. Dieses bietet ausschließlich eine nativen Erlang-Client an, erlaubt dafür aber auch direkt jegliche Erlang-Terme in der Datenbank zu speichern. Auch eine Hochverfügbarkeit ließe sich ähnlich zum Elixir-Node-Cluster konfigurieren und es wäre im Gegensatz zu Postgres kein komplexes Setup mit Failover, SQLProxy und SQL-Replication nötig.

## Kubernetes Ingress (TLS) vs integriertes Elixir TLS

Eine essenzielle Funktion, um breite Akzeptanz von Web-Anwendungen sicherzustellen, ist die Verschlüsselung des Datenverkehrs zwischen der Anwendung und dem Nutzer. Im Internet geschieht dies heutzutage meist über das "Transport Layer Security" Protokoll kurz [TLS](https://datatracker.ietf.org/wg/tls/documents/). Gerade die Übermittlung von sensiblen Daten wie Zahlungsinformationen sollte niemals unverschlüsselt passieren. Zudem identifiziert sich der Betreiber der Anwendung über TLS eindeutig gegenüber den Nutzern.

Verbindet man sich aus dem Internet von Außen zu einer Anwendung, welche über Kubernetes ausgerollt wurde, wird eine Verbindung zur Kubernetes [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) Komponente aufgebaut. Ingress stellt also HTTP- und HTTPS-Endpunkte bereit, um von außerhalb des Clusters Dienste innerhalb des Clusters erreichen zu können. Damit der Datenverkehr zwischen dem HTTPS-Endpunkt und dem Nutzer nun verschlüsselt werden kann, muss Ingress also TLS nutzen. Dazu muss im Base64 Format ein privater TLS-Schlüssel sowie ein privates TLS-Zertifikat angegeben werden. Dieses wird anschließend genutzt, um den Datenverkehr zu verschlüsseln. Jedoch ist es nun sehr wichtig zu beachten, des der TLS-Abschluss am Ingress-Endpunkt stattfindet. Weitere Verbindungen zu Diensten und Pods innerhalb des Clusters erfolgen im Klartext. 

Elixir bringt jedoch auch einen standardmäßig integrierten ["Plug"](https://hexdocs.pm/plug/https.html) mit, welcher den Datenverkehr über TLS verschlüsseln kann. Auch bei HTTPS-Abschluss via ELixir, muss wieder ein gültiges Zertifikat und der zugehörige private Schlüssel angegeben werden. Der Vorteil besteht darin, dass auch die Daten von Ingress zur Anwendung verschlüsselt übertragen werden. Dies wiederum führt zu weniger Angriffsvektoren, welche zum Ziel haben, Private Daten unbemerkt mitzuschneiden. Gerade in Zeiten, wo das konventionelle Konzept der Perimetersicherung vor allem in Cloudumgebungen immer weiter bröckelt, können solche Möglichkeiten hin zu einem modernen Zero-Trust-Ansatz helfen, mehr Sicherheit zu gewährleisten. Dabei wird auch innerhalb der Perimetersicherung bei Abfragen auf Ressourcen niemanden mehr vertraut.
Eine standardmäßige Verschlüsselung des Datenverkehrs zwischen Clusterknoten (Elixir Anwendungen) im internen Netzwerk schafft hier eine weitere Sicherheitsstufe. Noch interessanter wird dieser Ansatz, wenn von Ingress und Elixir verschiedenen TLS Zertifikate für die Verschlüsselung des Datenverkehrs kombiniert im Zwiebelprinzip verwendet werden.

## Database Migration K8s vs CI/CD

Die Datenbank Erstellung und Migration lässt sich auf verschiedene Arten durchführen. Eine Möglichkeit ist es diesen Prozess innerhalb von Kubernetes mithilfe von initContainern oder Jobs durchzuführen. Alternativ kann die Migration auch extern über einen kubectl Befehl erfolgen. Die Ausführung würde dann durch ein CI/CD System, wie z. B. GitHub Actions oder Jenkins erfolgen. Die Vor- und Nachteile jeder dieser Methoden sollen hier näher betrachtet werden.

Betrachten wir zunächst die Möglichkeiten innerhalb von Kubernetes, initContainers und Jobs. Init-Container werden vor dem Start der eigentlichen Container eines Pods ausgeführt. Die vorhergehenden Container müssen jeweils ihre Aufgabe erfolgreich abschließen bevor der nächste InitContainer bzw. die eigentlichen Container des Pods gestartet werden. Aufgrund der Tatsache, dass die InitContainer pro Pod ausgeführt werden, sind diese jedoch eher ungeeignet, da dies bedeuten würde, das die Datenbank Erstellung bzw. Migration für jedes der einzelnen Replica ausgeführt werden würde. Daher ist diese Option nur für Datenbank Migrationen bei Pods geeignet die keine weiteren Replicas besitzen.
Eine weitere Kubernetes basierte Alternative sind die Jobs. K8s Jobs erstellen einen temporären Pod, dessen Ausführungsstatus getrackt wird. Wenn die Ausführung des Pods erfolgreich war, wird der Job als completed markiert und kann bei angegebener TTL gelöscht werden. Vorteilhaft bei dieser Lösung ist, dass das Datenbank Provisioning ohne vorhandene Elixir Pods vorgenommen werden kann. Suboptimal ist, dass nur für das Provisioning ein extra Pod erstellt werden muss.

Alternativ zum Datenbank Provisioning innerhalb von Kubernetes, lassen sich analog zu Docker auch Befehle auf bestehenden Pods via `kubectl` ausführen. Dies kann genutzt werden um die Datenbank via Elixir zu provisionieren. Von Vorteil ist hier, dass die bestehenden Elixir Pods inklusive ihrer Datenbank Verbindungskonfiguration wiederverwendet werden können und keine umfangreiche Erweiterung der Kubernetes Service Definitions notwendig ist. Von Nachteil ist jedoch, dass die Ausführung der DB Provisionierung nur erfolgen kann, wenn die Elixir-Container bereits erstellt sind. Dies kann zu temporären Ausfällen der Anwendung während Schema-Migrations führen. Die Ausführung der Datenbank Provisionierung lässt sich in Kombination mit einem der o.g. CI/CD Systeme dann auch entsprechend automatisieren.

Aufgrund der Einfachheit und keinen nennenswerten Vorteilen gegenüber einer nativen Kubernetes Lösung für die Datenbank Provisionierung, haben wir uns für die `kubectl` basierte Lösung entschieden. Für ein Produktivsetup wäre aufgrund der möglichen Anwendungsausfälle aufgrund von Schema-Migrations, eine Kubernetes native Lösung besser geeignet, da das Deployment der neuen Version dann vom Erfolg der Schema Migration abhängig gemacht werden kann.

## Error-Handling K8s vs BeanVM

Sobald eine Anwendung ausgerollt wurde, wird ein weiteres wichtiges Thema interessant, welches unter anderem auch für die Hochverfügbarkeit der Anwendung, aber auch für die Robustheit eine große Rolle spielt. Die Rede ist von der Fehlerbehandlung und damit verbunden auch die Eigenschaft des sogenannten "self-healing". Dieses Kapitel soll diesen Themenkomplex nun beleuchten. Natürlich sollten gut entwickelte Anwendungen so gut wie nie in einen Fehlerzustand gelangen, doch kann dies meist nicht ausgeschlossen werden, was im Folgenden durch ein kurzes Beispiel motiviert werden soll. 

Gerade bei Cloud-Anwendungen, welche über Formularfelder viele Nutzereingaben zulassen, können oft nicht alle nötigen Sonderfälle behandelt bzw. validiert werden. Werden nun Eingaben so formuliert, dass keine serverseitige Behandlung der Eingabe mehr greift, kommt es meist zu einem Anwendungsfehler, welcher behandelt werden sollte. Dies sollte unbedingt passieren, da sich die Anwendung nun nicht mehr in einem sauberen Zustand befindet und dadurch eventuell weitere Angriffsvektoren möglich werden. Würde man die Serverseitige-Validierung abschalten, wäre natürlich die Wahrscheinlichkeit geringer, in einen Fehlerzustand zu gelangen, doch ist nun die Gefahr für erfolgreiche Angriffe noch größer, da nun jede Art von Schadcode einfach in die Anwendung eingeschleust werden kann. Fehlerbehandlung ist also nach wie vor essenziell. Die zuvor eingeführte Eigenschaft des "self-healings" soll dabei die Eigenschaft beschreiben, dass sich Anwendungen aus dieser Sackgasse, in welche sie durch den Fehlerzustand gelangt sind, selbst wieder befreien können. Dies kann, wie wir in den folgenden Abschnitten sehen werden von außen oder dank der Architektur von Erlang auch von innen auf Anwendungsebene passieren.

Zunächst soll jedoch die "self-healing" Eigenschaft von Kubernetes untersucht werden, welche standardmäßig integriert ist. Sobald eine containerisierte Anwendung bzw. eine Anwendungskomponente ausfällt, stellt Kubernetes sie auf Anwendungsebene neu bereit. Dafür wird zuvor ein gewünschter Zustand der Anwendung definiert, mit welchem der aktuelle Zustand abgeglichen wird. Weicht der aktuelle Zustand ab, wird eine Neubereitstellung angestoßen. Die Pods sind dabei erst wieder erreichbar, sobald sie nach einem Neustart einsatzbereit sind. Dadurch kann sichergestellt werden, dass Anwendungen nach einem Fehlerzustand weiterlaufen. Wie schnell deutlich wird, können Pods in Kubernetes Umgebungen also sehr schnell "sterben", was aber nicht weiter schlimm ist. Wie im Kapitel Hochverfügbares Elixir vs Single Node bereits erläutert wurde, laufen mehrere Replikas derselben Anwendung parallel. Diese können sich nun um weitere Anfragen an die Anwendung kümmern. Damit Kubernetes feststellen kann, ob ein Pod sich im gewünschten Zustand befindet, werden zwei Proben durchgeführt. Zum einen die sogenannte ["liveliness probe"](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/) und zum anderen die ["readiness probe"](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/). Die "liveliness probe" prüft den aktuellen Betriebsstatus eines Containers. Die "readiness probe" prüft, ob der Container auf Anfragen reagiert. Schlägt eine dieser Proben fehl, wird der Pod neu gestartet. Die Neustartrichtlinien können dabei selber konfiguriert werden. Die Kubernetes "self-Healing" Eigenschaft sichert also eine höhere Zuverlässigkeit der Anwendung zu. Jedoch ist dieser Ansatz natürlich sehr grob, aber dennoch effektiv. Es können aber dennoch Probleme auftreten. Ein Neustart von fehlerhaften Containern kann im schlimmsten Fall bis zu 5 Minuten dauern. Führt ein kritischer Fehler in der Anwendung dazu, dass alle Replikas neu gestartet werden müssen und eventuell an diesem Punkt die Infrastruktur ausgelastet ist, kann es dennoch zum Ausfall des kompletten Clusters kommen. An diesem Punkt wäre eine feingranularere Fehlerbehandlung der Anwendung ansich wünschenswert. Entwickler könnten dann im Fehlerfall selbst entscheiden, ob der Container, welcher die Anwendung bereitstellt, neu gestartet werden sollte oder nicht. Dank der BeamVM wird diese nicht so triviale Aufgabe möglich. 

Elixir verfolgt wie auch Erlang eine "Let it crash" Philosophie und schlägt damit einen komplett anderen Weg ein als andere Programmiersprachen. Die technische Idee dieser Philosophie ist dabei, dass sich sogenannte ["supervisor"](https://www.erlang.org/doc/man/supervisor.html) darum kümmern, die App neu zu starten, sobald die Anwendung in einen Fehlerzustand übergeht. Die "self-healing" Strategie ist dabei also sehr ähnlich zu der von Kubernetes, nur dass dies nun innerhalb der Anwendung möglich wird. Schon während der Programmierung wird dabei ein komplett anderes Programmierparadigma umgesetzt, als man es von anderen Programmiersprachen kennt. Man programmiert dabei nur für den positiven Fall und schaut später, wie man mit eventuellen Fehlern umgeht. Dies führt nicht nur zu kürzeren Code, sondern auch zu einer robusten und damit fehlertolerante Anwendung. Ein "supervisor" ist dabei ein Prozess, der andere Prozesse, so genannte Kindprozesse, überwacht. Ein Kindprozess kann dabei entweder ein anderer Supervisor oder ein Arbeitsprozess sein. Führt ein "supervisor" einen anderen "supervisor" aus, so ermöglicht dies den Aufbau einer hierarchischen Prozess-Sruktur welche "supervison-tree" genannt wird. Jeder "supervisor" verfügt über bestimmte Schnittstellenfunktionen und umfasst zudem Funktionen, welche für die Ablaufverfolgung und Fehlerberichterstattung genutzt werden. Mittels dieser Funktionen ist er in der Lage, seine Kindprozesse zu starten, anzuhalten sowie zu überwachen. Dabei können verschiedene Neustartstrategien vom Programmierer festgelegt werden. Kommt es also zu Fehlern in einem Prozess, beispielsweise durch einem Bug im Programm, wird dieser Prozess beendet. Der Prozess sendet dann ein `exit` Signal an seinen Supervisor und dieser kann dann entscheiden, ob er beispielsweise den Prozess Neustarten möchte oder den Prozess quasi verwirft, also nicht mehr neu startet. Alle anderen Prozesse laufen jedoch ungestört weiter. Funktionen von Elixir Programmen laufen dabei in eigenen leichtgewichtigen Prozessen der BeamVM, werden also zudem hochgradig parallel ausgeführt.

Die genannten Vorteile machen deutlich, weshalb Elixir perfekt für Cloudanwendungen genutzt werden kann. Elixir und Kubernetes ergänzen sich perfekt und ermöglichen es, das scheinbar unerreichbare Ziel der kompletten Ausfallsicherheit auf Anwendungsebene zu erreichen. 

![supervison-tree](https://github.com/Elixir2K8s/docs/blob/main/supervison-tree.png)


## Monitoring und Logging

Die kontinuierliche Überwachung einer Anwendung ist in der Entwicklungsphase eher weniger relevant. Hier reichen die `docker log` bzw. `kubectl logs` Befehle meist völlig aus. Soll die Anwendung hingegen produktiv ausgerollt werden ist eine umfangreichere Monitoring Lösung sinnvoll. 

Hierbei muss zuerst eine entsprechendes Logging Backend gefunden werden, z. B. Graylog Server. Das Logging Backend ist für das empfangen der Logging Daten aus allen möglichen Quellen zuständig, dazu können Kubernetes-Cluster zählen, Anwendungen selbst, syslogs, diverse Logging Agents und vieles mehr. Um die Logging Daten aus einer auf Kubernetes deployten Anwendung abzugreifen gibt es zwei Möglichkeiten.

Zum einen ist es möglich die Anwendung selbst logs an das Logging-Backend schicken zu lassen. Dies kann im Falle von Graylog, dann direkt im Graylog Extended Logging Format (GELF) geschehen. Vorteilhaft an dieser Lösung ist, dass intermediaries, wie z. B. ein Log Collector entfallen und kein aufwendiges Parsing der Logs erforderlich ist. Auch können wichtige Zusatzinformationen von der Anwendung direkt mitgeschickt werden. Nachteilhaft ist jedoch, dass K8s Cluster Level Informationen nicht enthalten sind, da diese außerhalb des Scopes der Anwendung sind. Dazu gehören Informationen über den genutzen Pod, Image, etc. etc. Auch kann es passieren das Crashes etc. nicht richtig getrackt werden, weil vergessen wurde Exceptions zu catchen und der Logging Agent dann mit crasht, da er auf Anwendungsebene läuft. So kann es schwieriger sein Crashursachen zu identifizieren. Auch muss die Anwendung zwigend über integriertes Logging verfügen, was nicht bei allen Anwendungen der Fall ist.

Um diese Probleme zu umgehen ist es möglich auf einen externen Logging Agent zu setzen, welcher auf K8s Cluster Ebene die Logs von allen Containern sammelt. Vorteilhaft ist hier, dass die genutzen Anwendung keine Unterstützung mehr für einen integrierten Logging Provider benötigen. Auch können hier Informationen auf Cluster Ebene mit übermittelt werden, bspw. welches Image ein bestimmter Pod nutzt oder was der jeweilige Hostname ist. Nachteilhaft ist jedoch, dass jede Anwendung oft ihr eigenes Logging Format besitzt und dies ein umfangreiches Parsing auf dem Logging Backend erfordert um die Daten später auswerten zu können.

Aus diesen Gründen kann es sinnvoll sein beide o.g. Logging Methoden zu nutzen. Wenn die Logging Agents entsprechend konfiguriert wurden und Daten an das Backend senden können auf diesem die Logdateien automatisiert ausgewertet werden. Hier kann dann ein zentralisiertes Monitoring und Alerting erfolgen. Beispielsweise lassen sich Dashboards für die Auswertung anlegen und automatisierte Alarme senden, wenn bestimmte Thresholds unter- bzw. überschritten werden.