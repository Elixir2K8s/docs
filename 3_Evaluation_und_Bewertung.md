# Evaluation und Bewertung

## Hochverfügbares Elixir vs Single Node
Immer mehr Alltagsanwendungen sind heutzutage über das Internet via Webbrowser erreichbar. Diese "Software as a Service" Produkte müssen dabei hohen Anforderungen gerecht werden. Im Mittelpunkt stehen beispielsweise Eigenschaften wie "Zero Downtime" und hohe Reaktionszeiten der Software. Das Synonym "Zero Downtime" bedeutet dabei, dass die Anwendung jederzeit verfügbar ist, also auch wenn nebenbei Software-Updates stattfinden oder die Datenbank migriert wird, die Anwendung verfügbar bleibt. Hohe Reaktionszeiten sind dabei maßgeblich für eine gute "User-Experience" verantwortlich. Diese ist wiederum eng verknüpft mit der durch den Benutzenden wahrgenommenen Qualität der Anwendung. Diese Hohe Software-Verfügbarkeit von verteilten Anwendungen kann dabei über zwei Wege erreicht werden. Man kann zum einen vertikal skalieren, indem man die Instanz, auf welcher die Anwendung läuft, mit mehr Ressourcen ausstattet. Oder man kann zum anderen horizontal skalieren, indem man einfach mehr Instanzen der Anwendung, sogenannte Replikationen, parallel betreibt. 

Genau an diesem Punkt kommt Kubernetes ins Spiel. Kubernetes ist genau für eine solche horizontale Skalierung ausgelegt. In den zuvor beschriebenen Deployment-Konfiguration kann angegeben werden, wie viele Replikas der Anwendung parallel laufen sollen. Dies wird dadurch bewerkstelligt, dass von der Anwendungskonfiguration sogenannte "Blueprints", also exakte "Klone" der Anwendung gestartet werden, welche dann über verschiedene IP-Adressen erreichbar sind. In diesen Anwendungskonfigurationen wiederum wird das container-Image der Anwendung angegeben, welches beispielsweise ein Docker Image sein kann, wie in der im Prototypen verwendeten Anwendung. Hällt man sich an die Namensgebung von Kubernetes, laufen die Anwendungen dann in sogenannten Pods. Ein [Pod](https://kubernetes.io/de/docs/concepts/workloads/pods/) ist also eine Abstraktion von einem oder mehreren Containern, welche gemeinsam dieselben Speicher- und Netzwerkressourcen nutzen, sowie eine gemeinsame Spezifikation für die Ausführung dieser Container teilen. Nun fehlt nur noch die Erklärung der zwei Fachbegriffe "Node" und Cluster um, auf die Hochverfügbarkeit von Elixir ansich eingehen zu können. Kubernetes führt "workload" bzw. Arbeitslast aus, indem es Container in Pods platziert, die anschließend auf ["Nodes"](https://kubernetes.io/docs/concepts/architecture/nodes/) ausgeführt werden. Jeder dieser Knoten wird von der Steuerungsebene verwaltet und enthält die für den Betrieb von Pods erforderlichen Dienste. Normalerweise werden dann mehrere dieser Knoten in einem Cluster, also einem Verbund bzw. einer Gruppe dieser Knoten betrieben, auf denen von Kubernetes verwaltete containerisierte Anwendungen laufen. (loadbalancer)

Elixir-Anwendungen lassen sich perfekt in dieses Konzept integrieren. Elixir besitzt dabei alle notwendigen verteilten Funktionen, welche benötigt werden, um ein Cluster zwischen den verschiedenen Instanzen der jeweiligen Anwendungen aufbauen zu können. Es werden noch nicht mal zusätzlichen Abhängigkeiten benötigt. Um so ein Cluster aufbauen zu können, muss jeder Anwendungsinstanz ein Name zugewiesen werden, welcher bestimmte Konventionen erfüllen muss. Anschließend können die erzeugten Knoten miteinander verbunden werden. Dies läuft über Angabe des festgelegten Namens über die ["connect"](https://hexdocs.pm/elixir/1.12/Node.html#connect/1) Funktion des Elixir-Node-Moduls. Der Name muss dabei folgendes Format haben <app-name>@<node-ip>. Dieser kann im Kubernetes Deployment über das Setzen der Umgebungsvariable [RELEASE_NODE](https://hexdocs.pm/mix/Mix.Tasks.Release.html) dynamisch zugewiesen werden.

![Elixir-Node-Cluster](https://github.com/Elixir2K8s/docs/blob/main/Libcluster.png)


## Hochverfügbare Datenbank vs einzelne Instanz

Nachdem die Elixir-Anwendung hochverfügbar gemacht wurde, ist die Postgres-Datenbank der letzte verbleibende Single Point of Failure, innerhalb des Kubernetes-Clusters.

Um diesen zu Eliminieren muss die Datenbank hochverfügbar gemacht werden. Hierfür sind mindestens zwei PostgresDB Pods erforderlich, wobei einer als Primary und die restlichen als Replica arbeiten. Für das Load Balancing und Failover zwischen den DB Pods kommt pgpool-II zum Einsatz. Das Failover zwischen Primary und Replicas wird durch den postgresql-repmgr verwaltet. Dieser promotet eine Replica zum neuen Primary, falls der bestehende Primary ausfällt.

Das [HA Postgres Setup von Bitnami](https://github.com/bitnami/charts/tree/master/bitnami/postgresql-ha) besteht aus einer Sammlung von K8s Service Definitions, die über einen Helm Chart installiert werden. Helm ist im übertragenen Sinne ein Paketmanager für Kubernetes Service Definitions, die eine Anwendung deployen. Um Helm in MicroK8s zu nutzen, muss Helm erst als Addon aktiviert werden.

Nachdem die Parameter des [Bitnami Postgres HA Helm Charts](https://github.com/bitnami/charts/tree/master/bitnami/postgresql-ha#global-parameters) wie gewünscht konfiguriert wurden kann dieser via Helm installiert werden und ist danach einsatzbereit.

Im Vergleich zur Variante mit einer einzelnen Postgres Instanz ist dies ein signifikanter Mehraufwand. bei der Konfiguration und Deployment, da man zusätzlich zu den eigenen Service Definitions einen Helm Chart hat, dessen Konfiguration es auch entsprechend zu warten gilt. Bei der einzelnen Datenbank hingegen kann das Deployment einfach zusammen mit der Elixir-Anwendung mit dem selben Befehl erfolgen, da die Service Definitions im gleichen Verzeichnis liegen. Auch bei der Konfiguration war durchaus weniger zu beachten, da die Service Definitions für die einzelne PostgresDB mit kompose aus der docker-compose Datei generiert werden konnten.

Betrachtet man den Aspekt der Hochverfügbarkeit bzw. Ausfallsicherheit ist es durchaus sinnvoll auf einen hochverfügbaren Postgres Helm Chart zu setzen, da einzelne Nodes im Kubernetes Cluster ausfallen können und dies bei einer einzelnen Datenbank zu einem temporären Komplettausfall der Anwendung führen würde. Da im Rahmen des Praktikums jedoch nur ein Single Node Kubernetes Cluster genutzt wird, bietet der Einsatz des Postgres HA Charts keine Vorteile unter dem Aspekt der physischen Ausfallsicherheit. Der einzige nennenswerte Vorteil des HA DB Setups in Kombination mit einem Single Node K8s Cluster ist die unterbrechungsfreie Upgrademöglichkeit der Datenbank, jedoch ist diese Funktionalität für ein Test Deployment vernachlässigbar.

Daher bleiben wir für das Test Deployment auf einem Single Node K8s Cluster bei einer einzelnen Postgres-Instanz.

## Database Migration K8s vs CI/CD

Die Datenbank Erstellung und Migration lässt sich auf verschiedene Arten durchführen. Eine Möglichkeit ist es diesen Prozess innerhalb von Kubernetes mithilfe von initContainern oder Jobs durchzuführen. Alternativ kann die Migration auch extern über einen kubectl Befehl erfolgen. Die Ausführung würde dann durch ein CI/CD System, wie z. B. GitHub Actions oder Jenkins erfolgen. Die Vor- und Nachteile jeder dieser Methoden sollen hier näher betrachtet werden.

Betrachten wir zunächst die Möglichkeiten innerhalb von Kubernetes, initContainers und Jobs. Init-Container werden vor dem Start der eigentlichen Container eines Pods ausgeführt. Die vorhergehenden Container müssen jeweils ihre Aufgabe erfolgreich abschließen bevor der nächste InitContainer bzw. die eigentlichen Container des Pods gestartet werden. Aufgrund der Tatsache, dass die InitContainer pro Pod ausgeführt werden, sind diese jedoch eher ungeeignet, da dies bedeuten würde, das die Datenbank Erstellung bzw. Migration für jedes der einzelnen Replica ausgeführt werden würde. Daher ist diese Option nur für Datenbank Migrationen bei Pods geeignet die keine weiteren Replicas besitzen.
Eine weitere Kubernetes basierte Alternative sind die Jobs. K8s Jobs erstellen einen temporären Pod, dessen Ausführungsstatus getrackt wird. Wenn die Ausführung des Pods erfolgreich war, wird der Job als completed markiert und kann bei angegebener TTL gelöscht werden. Vorteilhaft bei dieser Lösung ist, dass das Datenbank Provisioning ohne vorhandene Elixir Pods vorgenommen werden kann. Suboptimal ist, dass nur für das Provisioning ein extra Pod erstellt werden muss.

Alternativ zum Datenbank Provisioning innerhalb von Kubernetes, lassen sich analog zu Docker auch Befehle auf bestehenden Pods via `kubectl` ausführen. Dies kann genutzt werden um die Datenbank via Elixir zu provisionieren. Von Vorteil ist hier, dass die bestehenden Elixir Pods inklusive ihrer Datenbank Verbindungskonfiguration wiederverwendet werden können und keine umfangreiche Erweiterung der Kubernetes Service Definitions notwendig ist. Von Nachteil ist jedoch, dass die Ausführung der DB Provisionierung nur erfolgen kann, wenn die Elixir-Container bereits erstellt sind. Dies kann zu temporären Ausfällen der Anwendung während Schema-Migrations führen. Die Ausführung der Datenbank Provisionierung lässt sich in Kombination mit einem der o.g. CI/CD Systeme dann auch entsprechend automatisieren.

Aufgrund der Einfachheit und keinen nennenswerten Vorteilen gegenüber einer nativen Kubernetes Lösung für die Datenbank Provisionierung, haben wir uns für die `kubectl` basierte Lösung entschieden. Für ein Produktivsetup wäre aufgrund der möglichen Anwendungsausfälle aufgrund von Schema-Migrations, eine Kubernetes native Lösung besser geeignet, da das Deployment der neuen Version dann vom Erfolg der Schema Migration abhängig gemacht werden kann.

## Monitoring und Logging

Die kontinuierliche Überwachung einer Anwendung ist in der Entwicklungsphase eher weniger relevant. Hier reichen die `docker log` bzw. `kubectl logs` Befehle meist völlig aus. Soll die Anwendung hingegen produktiv ausgerollt werden ist eine umfangreichere Monitoring Lösung sinnvoll. 

Hierbei muss zuerst eine entsprechendes Logging Backend gefunden werden, z. B. Graylog Server. Das Logging Backend ist für das empfangen der Logging Daten aus allen möglichen Quellen zuständig, dazu können Kubernetes-Cluster zählen, Anwendungen selbst, syslogs, diverse Logging Agents und vieles mehr. Um die Logging Daten aus einer auf Kubernetes deployten Anwendung abzugreifen gibt es zwei Möglichkeiten.

Zum einen ist es möglich die Anwendung selbst logs an das Logging-Backend schicken zu lassen. Dies kann im Falle von Graylog, dann direkt im Graylog Extended Logging Format (GELF) geschehen. Vorteilhaft an dieser Lösung ist, dass intermediaries, wie z. B. ein Log Collector entfallen und kein aufwendiges Parsing der Logs erforderlich ist. Auch können wichtige Zusatzinformationen von der Anwendung direkt mitgeschickt werden. Nachteilhaft ist jedoch, dass K8s Cluster Level Informationen nicht enthalten sind, da diese außerhalb des Scopes der Anwendung sind. Dazu gehören Informationen über den genutzen Pod, Image, etc. etc. Auch kann es passieren das Crashes etc. nicht richtig getrackt werden, weil vergessen wurde Exceptions zu catchen und der Logging Agent dann mit crasht, da er auf Anwendungsebene läuft. So kann es schwieriger sein Crashursachen zu identifizieren. Auch muss die Anwendung zwigend über integriertes Logging verfügen, was nicht bei allen Anwendungen der Fall ist.

Um diese Probleme zu umgehen ist es möglich auf einen externen Logging Agent zu setzen, welcher auf K8s Cluster Ebene die Logs von allen Containern sammelt. Vorteilhaft ist hier, dass die genutzen Anwendung keine Unterstützung mehr für einen integrierten Logging Provider benötigen. Auch können hier Informationen auf Cluster Ebene mit übermittelt werden, bspw. welches Image ein bestimmter Pod nutzt oder was der jeweilige Hostname ist. Nachteilhaft ist jedoch, dass jede Anwendung oft ihr eigenes Logging Format besitzt und dies ein umfangreiches Parsing auf dem Logging Backend erfordert um die Daten später auswerten zu können.

Aus diesen Gründen kann es sinnvoll sein beide o.g. Logging Methoden zu nutzen. Wenn die Logging Agents entsprechend konfiguriert wurden und Daten an das Backend senden können auf diesem die Logdateien automatisiert ausgewertet werden. Hier kann dann ein zentralisiertes Monitoring und Alerting erfolgen. Beispielsweise lassen sich Dashboards für die Auswertung anlegen und automatisierte Alarme senden, wenn bestimmte Thresholds unter- bzw. überschritten werden.